{
 "cells": [],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [
     "\n",
     "import torch\n",
     "\n",
     "from e2cnn import gspaces\n",
     "from e2cnn import nn\n",
     "\n",
     "r2_act = gspaces.Rot2dOnR2(N=4)\n",
     "\n",
     "\n",
     "feat_type_in = nn.FieldType(r2_act, [r2_act.trivial_repr])\n",
     "\n",
     "feat_type_out = nn.FieldType(r2_act, [r2_act.regular_repr])\n",
     "\n",
     "feat_type_out = nn.FieldType(r2_act, 3*[r2_act.regular_repr])\n",
     "\n",
     "\n",
     "conv = nn.R2Conv(feat_type_in, feat_type_out, kernel_size=3)\n",
     "\n",
     "\n",
     "x = torch.randn(4, 1, 32, 32)\n",
     "x = nn.GeometricTensor(x, feat_type_in)\n",
     "\n",
     "assert isinstance(x.tensor, torch.Tensor)\n",
     "\n",
     "assert y.type == feat_type_out\n",
     "\n",
     "\n",
     "# for each group element\n",
     "for g in r2_act.testing_elements:\n",
     "    # transform the input with the current group element according to the input type\n",
     "    x_transformed = x.transform(g)\n",
     "    \n",
     "    # feed the transformed input in the convolutional layer\n",
     "    y_from_x_transformed = conv(x_transformed)\n",
     "    \n",
     "    # the result should be equivalent to rotating the output produced in the \n",
     "    # previous block according to the output type\n",
     "    y_transformed_from_x = y.transform(g)\n",
     "    assert torch.allclose(y_from_x_transformed.tensor, y_transformed_from_x.tensor, atol=1e-5), g\n",
     "\n",
     "\n",
     "relu = nn.ReLU(feat_type_out)\n",
     "\n",
     "z = relu(y)\n",
     "\n",
     "# for each group element\n",
     "for g in r2_act.testing_elements:\n",
     "    y_transformed = y.transform(g)\n",
     "    z_from_y_transformed = relu(y_transformed)\n",
     "    \n",
     "    z_transformed_from_y = z.transform(g)\n",
     "    \n",
     "    assert torch.allclose(z_from_y_transformed.tensor, z_transformed_from_y.tensor, atol=1e-5), g\n",
     "\n",
     "\n",
     "layer1 = nn.R2Conv(feat_type_in, feat_type_out, kernel_size=3)\n",
     "layer2 = nn.ReLU(feat_type_in) # the input type of the ReLU should be the output type of the convolution\n",
     "\n",
     "x = nn.GeometricTensor(torch.randn(3, 1, 7, 7), feat_type_in)\n",
     "\n",
     "try:\n",
     "    y = layer2(layer1(x))\n",
     "except AssertionError as e:\n",
     "    print(e)\n",
     "\n",
     "feat_type_in = nn.FieldType(r2_act, [r2_act.trivial_repr])\n",
     "feat_type_hid = nn.FieldType(r2_act, 8*[r2_act.regular_repr])\n",
     "feat_type_out = nn.FieldType(r2_act, 2*[r2_act.regular_repr])\n",
     "\n",
     "model = nn.SequentialModule(\n",
     "    nn.R2Conv(feat_type_in, feat_type_hid, kernel_size=3),\n",
     "    nn.InnerBatchNorm(feat_type_hid),\n",
     "    nn.ReLU(feat_type_hid),\n",
     "    nn.R2Conv(feat_type_hid, feat_type_hid, kernel_size=3),\n",
     "    nn.InnerBatchNorm(feat_type_hid),\n",
     "    nn.ReLU(feat_type_hid),\n",
     "    nn.R2Conv(feat_type_hid, feat_type_out, kernel_size=3),\n",
     ").eval()\n",
     "\n",
     "\n",
     "x = torch.randn(1, 1, 17, 17)\n",
     "x = nn.GeometricTensor(x, feat_type_in)\n",
     "\n",
     "y = model(x)\n",
     "\n",
     "# for each group element\n",
     "for g in r2_act.testing_elements:\n",
     "    x_transformed = x.transform(g)\n",
     "    y_from_x_transformed = model(x_transformed)\n",
     "    \n",
     "    y_transformed_from_x = y.transform(g)\n",
     "    \n",
     "    assert torch.allclose(y_from_x_transformed.tensor, y_transformed_from_x.tensor, atol=1e-5), g\n",
     "\n",
     "avgpool = nn.PointwiseAvgPool(feat_type_out, 11)\n",
     "\n",
     "y = avgpool(model(x))\n",
     "\n",
     "print(y.shape)\n",
     "\n",
     "invariant_map = nn.GroupPooling(feat_type_out)\n",
     "\n",
     "y = invariant_map(avgpool(model(x)))\n",
     "\n",
     "for i in range(4):\n",
     "    print(f'rotation by {i}*pi/2:', y.transform(i).tensor[0, ...].detach().numpy().squeeze())\n",
     "\n",
     "# for each group element\n",
     "for g in r2_act.testing_elements:\n",
     "    # rotated the input image\n",
     "    x_transformed = x.transform(g)\n",
     "    y_from_x_transformed = invariant_map(avgpool(model(x_transformed)))\n",
     "    \n",
     "    y_transformed_from_x = y # no .transform(g) needed since y should be invariant!\n",
     "    \n",
     "    # check that the output did not change\n",
     "    # note that here we are not rotating the original output y as before\n",
     "    assert torch.allclose(y_from_x_transformed.tensor, y_transformed_from_x.tensor, atol=1e-6), g\n",
     "\n",
     "\n",
     "feat_type_out = nn.FieldType(r2_act, [r2_act.irrep(1)])\n",
     "\n",
     "import matplotlib.pyplot as plt\n",
     "import numpy as np\n",
     "\n",
     "feat_type_in = nn.FieldType(r2_act, [r2_act.trivial_repr])\n",
     "feat_type_hid = nn.FieldType(r2_act, 8*[r2_act.regular_repr])\n",
     "\n",
     "model = nn.SequentialModule(\n",
     "    nn.R2Conv(feat_type_in, feat_type_hid, kernel_size=3),\n",
     "    nn.InnerBatchNorm(feat_type_hid),\n",
     "    nn.ReLU(feat_type_hid),\n",
     "    nn.R2Conv(feat_type_hid, feat_type_hid, kernel_size=3),\n",
     "    nn.InnerBatchNorm(feat_type_hid),\n",
     "    nn.ReLU(feat_type_hid),\n",
     "    nn.R2Conv(feat_type_hid, feat_type_out, kernel_size=3),\n",
     ").eval()\n",
     "\n",
     "S = 11\n",
     "x = torch.randn(1, 1, S, S)\n",
     "x = nn.GeometricTensor(x, feat_type_in)\n",
     "\n",
     "fig, axs = plt.subplots(1, r2_act.fibergroup.order(), sharex=True, sharey=True, figsize=(16, 4))\n",
     "\n",
     "X, Y = np.meshgrid(range(S-6), range(S-7, -1, -1))\n",
     "\n",
     "# for each group element\n",
     "for i, g in enumerate(r2_act.testing_elements):\n",
     "    # transform the input\n",
     "    x_transformed = x.transform(g)\n",
     "    \n",
     "    y = model(x_transformed)\n",
     "    y = y.tensor.detach().numpy().squeeze()\n",
     "    \n",
     "    # plot the output vector field\n",
     "    axs[i].quiver(X, Y, y[0, ...], y[1, ...], units='xy')\n",
     "    axs[i].set_title(g*90)\n",
     "    \n",
     "plt.show()\n",
     "\n",
     "\n",
     "norm_relu = nn.NormNonLinearity(feat_type_out, 'n_relu')\n",
     "\n",
     "y = norm_relu(model(x))\n",
     "\n",
     "for g in r2_act.testing_elements:\n",
     "    x_transformed = x.transform(g)\n",
     "    y_from_x_transformed = norm_relu(model(x_transformed))\n",
     "    \n",
     "    y_transformed_from_x = y.transform(g)\n",
     "    \n",
     "    assert torch.allclose(y_from_x_transformed.tensor, y_transformed_from_x.tensor, atol=1e-5), g\n",
     "\n",
     "feat_type_out = nn.FieldType(r2_act, 2*[r2_act.trivial_repr] + 2*[r2_act.regular_repr] + 1*[r2_act.irrep(1)])\n",
     "\n",
     "scalar_fields = nn.FieldType(r2_act, 2*[r2_act.trivial_repr])\n",
     "regular_fields = nn.FieldType(r2_act, 2*[r2_act.regular_repr])\n",
     "vector_field = nn.FieldType(r2_act, 1*[r2_act.irrep(1)])\n",
     "feat_type_out = scalar_fields + regular_fields + vector_field\n",
     "\n",
     "\n",
     "\n",
     "relu = nn.ReLU(scalar_fields + regular_fields)\n",
     "norm_relu = nn.NormNonLinearity(vector_field)\n",
     "\n",
     "nonlinearity = nn.MultipleModule(\n",
     "                    feat_type_out,\n",
     "                    ['relu']*len(scalar_fields+regular_fields) + ['norm']*len(vector_field),\n",
     "                    [(relu, 'relu'), (norm_relu, 'norm')]\n",
     ")\n",
     "\n",
     "model = nn.SequentialModule(\n",
     "    nn.R2Conv(feat_type_in, feat_type_hid, kernel_size=3),\n",
     "    nn.InnerBatchNorm(feat_type_hid),\n",
     "    nn.ReLU(feat_type_hid),\n",
     "    nn.R2Conv(feat_type_hid, feat_type_out, kernel_size=3),\n",
     "    nonlinearity,\n",
     ").eval()\n",
     "\n",
     "x = torch.randn(1, 1, 17, 17)\n",
     "x = nn.GeometricTensor(x, feat_type_in)\n",
     "\n",
     "y = model(x)\n",
     "\n",
     "for g in r2_act.testing_elements:\n",
     "    x_transformed = x.transform(g)\n",
     "    y_from_x_transformed = model(x_transformed)\n",
     "    \n",
     "    y_transformed_from_x = y.transform(g)\n",
     "    \n",
     "    assert torch.allclose(y_from_x_transformed.tensor, y_transformed_from_x.tensor, atol=1e-5), g\n"
    ],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}